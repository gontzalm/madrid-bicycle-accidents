{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Analysis of Traffic Accidents in Madrid Involving Bicycles\n",
    "\n",
    "Project Description goes here\n",
    "\n",
    "## Getting the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../datasets\n",
    "%cd ../datasets\n",
    "!curl -L -o dataset_#1.xlsx https://datos.madrid.es/egob/catalogo/300110-[1-17:2]-accidentes-bicicleta.xlsx\n",
    "%cd ../notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Datasets with Pandas\n",
    "General imports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Datasets to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import each of the datasets and store them in a list. Then, concat the dfs and show head()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of victims involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Victims in accidents involving bicycles between 2010 and 2018: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating the DataFrame\n",
    "Show columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_cols = [\"Date\", \"Hour Range\", \"Day of Week\", \"District\", \"Location\", \"No.\", \"Report No.\", \"Weather: Hail\", \"Weather: Ice\",\"Weather: Rain\", \"Weather: Fog\", \"Weather: Dry\", \"Weather: Snow\", \"Road: Wet\", \"Road: Oil\", \"Road: Mud\", \"Road: Gravel\", \"Road: Ice\", \"Road: Dry and clean\", \"Victims\", \"Accident Type\", \"Vehicle Type\", \"Person Type\", \"Gender\", \"Harmfulness\", \"Age Range\", \"* Victims\"]\n",
    "\n",
    "df.columns = eng_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some colums dont convey much info etc etc. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"`Vehicle Type`.str.strip() != 'BICICLETA'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets drop unnecessary info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Day of Week\", \"Report No.\", \"Weather: Hail\", \"Vehicle Type\", \"* Victims\"], inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's translate the values. See the unique values in the columns we want to translate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5, df.shape[1]):\n",
    "    print(f\"{df.iloc[:, i].name}: {df.iloc[:, i].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip the strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Accident Type\", \"Person Type\", \"Harmfulness\", \"Age Range\"]] = df[[\"Accident Type\", \"Person Type\", \"Harmfulness\", \"Age Range\"]].transform(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create translation dictionaries to map to each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes/No dict for the first columns\n",
    "yn_dict = {\"SI\": \"Yes\", \"NO\": \"No\"}\n",
    "\n",
    "# Translate first columns\n",
    "for i in range(5, 17):\n",
    "    df.replace({df.iloc[:,i].name: yn_dict}, inplace=True)\n",
    "\n",
    "# English translation for the rest of the columns\n",
    "acc_type_eng = [\"Crash with static object\", \"Fall off bicycle\", \"Run over\", \"Double collision\", \"Fall off motorcycle\", \"Bus passenger fall\", \"Multiple collision\", \"Other causes\", \"Fall off moped\", \"Overturn\"]\n",
    "person_type_eng = [\"Driver\", \"Accompanying\", \"Witness\"]\n",
    "gender_eng = [\"W\", \"M\", \"Not assigned\"]\n",
    "harmfulness_eng = [\"Seriously injured\", \"Slightly injured\", \"Uninjured\", \"Not assigned\", \"Killed\"]\n",
    "age_range_eng = [\"21-24\", \"25-29\", \"18-20\", \"30-34\", \"45-49\", \"65-69\", \"35-39\", \"55-59\", \"50-54\", \"40-44\", \"10-14\", \"15-17\", \"6-9\", \"60-64\", \"0-5\", \"75+\", \"Unknown\", \"70-74\"]\n",
    "eng_list = [acc_type_eng, person_type_eng, gender_eng, harmfulness_eng, age_range_eng]\n",
    "\n",
    "# Create the translation dictionaries and translate the rest of the columns\n",
    "for i in range(18, df.shape[1]):\n",
    "    esp_list = df.iloc[:, i].unique()\n",
    "    dict = {k: v for k, v in zip(esp_list, eng_list[i - 18])}\n",
    "    df.replace({df.iloc[:,i].name: dict}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "Let's check for null entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only null values in the \"Victims\" column. Let's see how many accident entries have a null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Victims\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a significant amount of data ($\\approx 13$%), so fill NaN values.\n",
    "Let's see wich type of person was involved in this accidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Victims\"].isnull()].groupby(\"Person Type\")[\"Date\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity, let's suppose drivers were the only ones injured in their accidents, and accompanyings were involved in accidents with two victims. We'll discard all witnesses as they probably only reported a crash but weren't involved in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.loc[df[\"Person Type\"] == \"Driver\", \"Victims\"] = df.loc[df[\"Person Type\"] == \"Driver\", \"Victims\"].fillna(1)\n",
    "\n",
    "df.loc[df[\"Person Type\"] == \"Accompanying\", \"Victims\"] = df.loc[df[\"Person Type\"] == \"Accompanying\", \"Victims\"].fillna(2)\n",
    "\n",
    "df.drop(index=df.query(\"`Person Type` == 'Witness'\").index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rearanging the DataFrame\n",
    "Rearange the weather and road conditions data so it is contained in two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Weather\"] = df.apply(lambda row: row.iloc[5:11][row.iloc[5:11] == \"Yes\"].index[0].split(\" \")[-1], axis=\"columns\")\n",
    "\n",
    "df[\"Road condition\"] = df.apply(lambda row: row.iloc[11:17][row.iloc[11:17] == \"Yes\"].index[0].split(\" \")[-1], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second operation gives an error because:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"`Road: Wet` == 'No' & `Road: Oil` == 'No' & `Road: Mud` == 'No' & `Road: Gravel` == 'No' & `Road: Ice` == 'No' & `Road: Dry and clean` == 'No'\")[\"Date\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets suppose those days were normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"Road: Wet\"] == \"No\") & (df[\"Road: Oil\"] == \"No\") & (df[\"Road: Mud\"] == \"No\") & (df[\"Road: Gravel\"] == \"No\") & (df[\"Road: Ice\"] == \"No\") & (df[\"Road: Dry and clean\"] == \"No\")][\"Road: Dry and clean\"] = \"Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for i in range(9):\n",
    "    curr_df = pd.read_excel(\"../datasets/dataset_\" + str(2*i + 1) + \".xlsx\")\n",
    "    df_list.append(curr_df)\n",
    "    \n",
    "df = pd.concat([df_list[i] for i in range(9)], ignore_index=True)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}